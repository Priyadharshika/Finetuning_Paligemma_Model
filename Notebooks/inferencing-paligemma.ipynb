{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":279051,"sourceType":"modelInstanceVersion","modelInstanceId":239038,"modelId":260701},{"sourceId":279328,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":239276,"modelId":260939},{"sourceId":279355,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":239299,"modelId":260962}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q datasets lightning\n!pip install huggingface_hub  # Install if not already installed\n!pip install rouge_score\n!pip install zss","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-11T11:10:59.767553Z","iopub.execute_input":"2025-03-11T11:10:59.767891Z","iopub.status.idle":"2025-03-11T11:11:24.484050Z","shell.execute_reply.started":"2025-03-11T11:10:59.767857Z","shell.execute_reply":"2025-03-11T11:11:24.482459Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.29.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.12.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2025.1.31)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rouge_score) (2024.2.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=6576f4b4701219107d5a79deee6687832fd12c98803eee57858cb3ed015f48e3\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nCollecting zss\n  Downloading zss-1.2.0.tar.gz (9.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from zss) (1.17.0)\nBuilding wheels for collected packages: zss\n  Building wheel for zss (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for zss: filename=zss-1.2.0-py3-none-any.whl size=6725 sha256=026ad250cd8331d5b68d55aa711058f7242b009958889fb95518ba76f106e541\n  Stored in directory: /root/.cache/pip/wheels/f6/61/2a/cf33ab7301cc318a13418d9a805c1832be561b46e7d9337625\nSuccessfully built zss\nInstalling collected packages: zss\nSuccessfully installed zss-1.2.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import re\nimport json\nfrom torch.utils.data import Dataset\nfrom typing import Any, List, Dict\nimport random\nfrom datasets import load_dataset\nfrom huggingface_hub import login\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoProcessor, PaliGemmaForConditionalGeneration\nfrom nltk.metrics.distance import edit_distance\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom rouge_score import rouge_scorer\nfrom sklearn.metrics import f1_score\nimport zss  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T11:11:24.485323Z","iopub.execute_input":"2025-03-11T11:11:24.485717Z","iopub.status.idle":"2025-03-11T11:11:51.539379Z","shell.execute_reply.started":"2025-03-11T11:11:24.485688Z","shell.execute_reply":"2025-03-11T11:11:51.538037Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Constants\nREPO_ID = \"google/paligemma-3b-mix-224\"\n#FINETUNED_MODEL_ID_BASE = \"xxxxxxxxxxxxxxxx\"\n#FINETUNED_MODEL_ID = \"xxxxxxxxxxx\"\nMAX_LENGTH = 512\nDATASET_NAME = \"naver-clova-ix/cord-v2\"\n#TOKEN = \"xxxxxxxxxxxxxxxxxxxxxx\"\nPROMPT = \"extract JSON.\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(\n        self,\n        dataset_name_or_path: str,\n        split: str = \"train\",\n        sort_json_key: bool = True,\n    ):\n        super().__init__()\n\n        self.split = split\n        self.sort_json_key = sort_json_key\n\n        self.dataset = load_dataset(dataset_name_or_path, split=self.split)\n        self.dataset_length = len(self.dataset)\n\n        self.gt_token_sequences = []\n        for sample in self.dataset:\n            ground_truth = json.loads(sample[\"ground_truth\"])\n            if \"gt_parses\" in ground_truth:  # when multiple ground truths are available, e.g., docvqa\n                assert isinstance(ground_truth[\"gt_parses\"], list)\n                gt_jsons = ground_truth[\"gt_parses\"]\n            else:\n                assert \"gt_parse\" in ground_truth and isinstance(ground_truth[\"gt_parse\"], dict)\n                gt_jsons = [ground_truth[\"gt_parse\"]]\n\n            self.gt_token_sequences.append(\n                [\n                    self.json2token(\n                        gt_json,\n                        sort_json_key=self.sort_json_key,\n                    )\n                    for gt_json in gt_jsons  # load json from list of json\n                ]\n            )\n\n    def json2token(self, obj: Any, sort_json_key: bool = True):\n        \"\"\"\n        Convert an ordered JSON object into a token sequence\n        \"\"\"\n        if type(obj) == dict:\n            if len(obj) == 1 and \"text_sequence\" in obj:\n                return obj[\"text_sequence\"]\n            else:\n                output = \"\"\n                if sort_json_key:\n                    keys = sorted(obj.keys(), reverse=True)\n                else:\n                    keys = obj.keys()\n                for k in keys:\n                    output += (\n                        fr\"<s_{k}>\"\n                        + self.json2token(obj[k], sort_json_key)\n                        + fr\"</s_{k}>\"\n                    )\n                return output\n        elif type(obj) == list:\n            return r\"<sep/>\".join(\n                [self.json2token(item, sort_json_key) for item in obj]\n            )\n        else:\n            obj = str(obj)\n            return obj\n\n    def __len__(self) -> int:\n        return self.dataset_length\n\n    def __getitem__(self, idx: int) -> Dict:\n        #Returns one item of the dataset.\n        #Returns:\n            #image : the original Receipt image\n            #target_sequence : tokenized ground truth sequence\n        sample = self.dataset[idx]\n\n        # inputs\n        image = sample[\"image\"]\n        target_sequence = random.choice(self.gt_token_sequences[idx])  # can be more than one, e.g., DocVQA Task 1\n        print(target_sequence)\n        return image, target_sequence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T11:11:51.540840Z","iopub.execute_input":"2025-03-11T11:11:51.541741Z","iopub.status.idle":"2025-03-11T11:11:51.562100Z","shell.execute_reply.started":"2025-03-11T11:11:51.541697Z","shell.execute_reply":"2025-03-11T11:11:51.560105Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def run_inference(dataset, processor, model, test_custom_dataset):\n    total_levenshtein_distance = 0\n    total_bleu_score = 0\n    total_rouge1 = 0\n    total_rouge2 = 0\n    total_rougeL = 0\n    num_samples = 1 #len(dataset[\"test\"])\n    results = []\n\n    for i in range(1):\n        test_example = dataset[\"test\"][i]\n        test_image = test_example[\"image\"]\n        _,target_sequence = test_custom_dataset[i]\n        \n        inputs = processor(text=PROMPT, images=test_image, return_tensors=\"pt\")\n        for k,v in inputs.items():\n            print(k,v.shape)\n            \n        generated_ids = model.generate(**inputs, max_new_tokens=MAX_LENGTH)    \n        image_token_index = model.config.image_token_index\n        num_image_tokens = len(generated_ids[generated_ids==image_token_index])\n        num_text_tokens = len(processor.tokenizer.encode(PROMPT))\n        num_prompt_tokens = num_image_tokens + num_text_tokens + 2\n        generated_text = processor.batch_decode(generated_ids[:, num_prompt_tokens:], skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n        print('generated_text',generated_text)\n        \n        generated_json = token2json(generated_text)\n        actual_json = token2json(target_sequence)\n        levenshtein_distance = edit_distance(str(generated_json), str(actual_json))\n        bleu_score = compute_bleu(str(generated_json), str(actual_json))\n        rouge_scores = compute_rouge(str(generated_json), str(actual_json))\n\n        total_levenshtein_distance += levenshtein_distance\n        total_bleu_score += bleu_score\n        total_rouge1 += rouge_scores[\"rouge1\"].fmeasure\n        total_rouge2 += rouge_scores[\"rouge2\"].fmeasure\n        total_rougeL += rouge_scores[\"rougeL\"].fmeasure\n\n        results.append({\n            \"sample\": i + 1,\n            \"generated_json\": generated_json,\n            \"actual_json\": actual_json,\n            \"levenshtein_distance\": levenshtein_distance,\n            \"bleu_score\": bleu_score,\n            \"rouge1\": rouge_scores[\"rouge1\"].fmeasure,\n            \"rouge2\": rouge_scores[\"rouge2\"].fmeasure,\n            \"rougeL\": rouge_scores[\"rougeL\"].fmeasure,\n        })\n    \n    avg_levenshtein_distance = total_levenshtein_distance / num_samples\n    avg_bleu_score = total_bleu_score / num_samples\n    avg_rouge1 = total_rouge1 / num_samples\n    avg_rouge2 = total_rouge2 / num_samples\n    avg_rougeL = total_rougeL / num_samples\n    \n    return results, avg_levenshtein_distance, avg_bleu_score, avg_rouge1, avg_rouge2, avg_rougeL\n\n\ndef save_results(results, avg_metrics, filename=\"inference_results.txt\"):\n    with open(filename, \"w\") as f:\n        for res in results:\n            f.write(f\"Sample {res['sample']}:\\n\")\n            f.write(f\"Generated JSON: {res['generated_json']}\\n\")\n            f.write(f\"Actual JSON: {res['actual_json']}\\n\")\n            f.write(f\"Levenshtein Distance: {res['levenshtein_distance']}\\n\")\n            f.write(f\"BLEU Score: {res['bleu_score']}\\n\")\n            f.write(f\"ROUGE Scores: R1={res['rouge1']}, R2={res['rouge2']}, RL={res['rougeL']}\\n\\n\")\n        f.write(f\"Average Metrics: LD={avg_metrics[0]}, BLEU={avg_metrics[1]}, ROUGE-1={avg_metrics[2]}, ROUGE-2={avg_metrics[3]}, ROUGE-L={avg_metrics[4]}\\n\")\n    print(f\"Results saved to {filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T11:11:51.564046Z","iopub.execute_input":"2025-03-11T11:11:51.564426Z","iopub.status.idle":"2025-03-11T11:11:51.604237Z","shell.execute_reply.started":"2025-03-11T11:11:51.564388Z","shell.execute_reply":"2025-03-11T11:11:51.602715Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\ndef token2json(tokens, is_inner_value=False, added_vocab=None):\n        #Convert a (generated) token sequence into an ordered JSON format.\n        if added_vocab is None:\n            added_vocab = processor.tokenizer.get_added_vocab()\n\n        output = {}\n\n        while tokens:\n            start_token = re.search(r\"<s_(.*?)>\", tokens, re.IGNORECASE)\n            if start_token is None:\n                break\n            key = start_token.group(1)\n            key_escaped = re.escape(key)\n\n            end_token = re.search(rf\"</s_{key_escaped}>\", tokens, re.IGNORECASE)\n            start_token = start_token.group()\n            if end_token is None:\n                tokens = tokens.replace(start_token, \"\")\n            else:\n                end_token = end_token.group()\n                start_token_escaped = re.escape(start_token)\n                end_token_escaped = re.escape(end_token)\n                content = re.search(\n                    f\"{start_token_escaped}(.*?){end_token_escaped}\", tokens, re.IGNORECASE | re.DOTALL\n                )\n                if content is not None:\n                    content = content.group(1).strip()\n                    if r\"<s_\" in content and r\"</s_\" in content:  # non-leaf node\n                        value = token2json(content, is_inner_value=True, added_vocab=added_vocab)\n                        if value:\n                            if len(value) == 1:\n                                value = value[0]\n                            output[key] = value\n                    else:  # leaf nodes\n                        output[key] = []\n                        for leaf in content.split(r\"<sep/>\"):\n                            leaf = leaf.strip()\n                            if leaf in added_vocab and leaf[0] == \"<\" and leaf[-2:] == \"/>\":\n                                leaf = leaf[1:-2]  # for categorical special tokens\n                            output[key].append(leaf)\n                        if len(output[key]) == 1:\n                            output[key] = output[key][0]\n\n                tokens = tokens[tokens.find(end_token) + len(end_token) :].strip()\n                if tokens[:6] == r\"<sep/>\":  # non-leaf nodes\n                    return [output] + token2json(tokens[6:], is_inner_value=True, added_vocab=added_vocab)\n\n        if len(output):\n            return [output] if is_inner_value else output\n        else:\n            return [] if is_inner_value else {\"text_sequence\": tokens}\n            \ndef compute_bleu(generated, actual):\n    return sentence_bleu([actual.split()], generated.split())\n\n\ndef compute_rouge(generated, actual):\n    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n    return scorer.score(generated, actual)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T11:11:51.605482Z","iopub.execute_input":"2025-03-11T11:11:51.605905Z","iopub.status.idle":"2025-03-11T11:11:51.625912Z","shell.execute_reply.started":"2025-03-11T11:11:51.605833Z","shell.execute_reply":"2025-03-11T11:11:51.624710Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    test_custom_dataset = CustomDataset(\"naver-clova-ix/cord-v2\", split=\"test\")\n    dataset = load_dataset(DATASET_NAME)\n    login(TOKEN)\n    processor = AutoProcessor.from_pretrained(REPO_ID)\n    model = PaliGemmaForConditionalGeneration.from_pretrained(FINETUNED_MODEL_ID_BASE)\n    results, *avg_metrics = run_inference(dataset, processor, model,test_custom_dataset)\n    save_results(results, avg_metrics)\n    print(f\"Evaluation Metrics: {avg_metrics}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T11:12:50.343715Z","iopub.execute_input":"2025-03-11T11:12:50.344042Z","iopub.status.idle":"2025-03-11T11:16:36.398991Z","shell.execute_reply.started":"2025-03-11T11:12:50.344017Z","shell.execute_reply":"2025-03-11T11:16:36.397374Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c88c00796df8423484d885c2072b309c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0471aacd18d64f3983a7baa17889d87d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/62.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2270523c5a7d4a0b9d9474ea967827ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f47e405584a04a7ca5783c3a9a978150"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b7ccecf860e4dac9683b4adca8bbf33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e0da735bedf4d1b8bcd1b784cc6488b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87645f9ede534a4abbc274b39d08fb9c"}},"metadata":{}},{"name":"stderr","text":"`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\nGemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n`config.hidden_activation` if you want to override this behaviour.\nSee https://github.com/huggingface/transformers/pull/29402 for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"931ceaeabba44e8aa647e3834ed8d3eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2134497925b54ca79f0b781103263382"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/45.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8df7a8888e234229b83a070ef5d2edfb"}},"metadata":{}},{"name":"stderr","text":"You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n","output_type":"stream"},{"name":"stdout","text":"<s_total><s_total_price>60.000</s_total_price><s_menuqty_cnt>2.00</s_menuqty_cnt><s_creditcardprice>60.000</s_creditcardprice></s_total><s_sub_total><s_tax_price>5.455</s_tax_price><s_subtotal_price>60.000</s_subtotal_price><s_discount_price>-60.000</s_discount_price></s_sub_total><s_menu><s_price>60.000</s_price><s_num>901016</s_num><s_nm>-TICKET CP</s_nm><s_itemsubtotal>60.000</s_itemsubtotal><s_cnt>2</s_cnt></s_menu>\ninput_ids torch.Size([1, 261])\nattention_mask torch.Size([1, 261])\npixel_values torch.Size([1, 3, 224, 224])\ngenerated_text <s_total><s_total_price>60.000</s_total_price><s_menuqty_cnt>2</s_menuqty_cnt><s_cashprice>60.000</s_cashprice></s_total><s_sub_total><s_tax_price>5.400</s_tax_price><s_subtotal_price>54.400</s_subtotal_price></s_sub_total><s_menu><s_price>60.000</s_price><s_nm>TICKET CP</s_nm><s_cnt>2</s_cnt></s_menu>\nResults saved to inference_results.txt\nEvaluation Metrics: [89.0, 0.18777843231751812, 0.7428571428571429, 0.5882352941176471, 0.7428571428571429]\n","output_type":"stream"}],"execution_count":7}]}